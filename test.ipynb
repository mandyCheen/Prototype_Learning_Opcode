{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['human', 'interface', 'computer'], ['survey', 'user', 'computer', 'system', 'response', 'time'], ['eps', 'user', 'interface', 'system'], ['system', 'human', 'system', 'eps'], ['user', 'response', 'time'], ['trees'], ['graph', 'trees'], ['graph', 'minors', 'trees'], ['graph', 'minors', 'survey']]\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "print(common_texts)\n",
    "model = Word2Vec(sentences=common_texts, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00515824 -0.00667093 -0.00777985  0.00831395 -0.00198311 -0.00685763\n",
      " -0.004156    0.00514612 -0.00287025 -0.00375112  0.00162205 -0.00277737\n",
      " -0.00158498  0.00107491 -0.0029791   0.00852259  0.00391245 -0.00996273\n",
      "  0.00626203 -0.00675688  0.00076973  0.00440594 -0.00510536 -0.00211149\n",
      "  0.00809862 -0.00424544 -0.00763923  0.00926151 -0.00215633 -0.00472126\n",
      "  0.00857413  0.004285    0.00432652  0.00928812 -0.00845636  0.00525736\n",
      "  0.00204014  0.00418991  0.00169856  0.00446587  0.00448803  0.00610689\n",
      " -0.00320334 -0.0045775  -0.00042668  0.00253472 -0.00326443  0.00606007\n",
      "  0.00415574  0.00776761  0.00257027  0.00811983 -0.00138775  0.00808106\n",
      "  0.00371846 -0.00805045 -0.00393514 -0.00247284  0.00489494 -0.0008725\n",
      " -0.00283201  0.00783675  0.00932652 -0.00161556 -0.00516125 -0.00470358\n",
      " -0.00484793 -0.00960655  0.00137255 -0.00422656  0.00252769  0.00561666\n",
      " -0.00406748 -0.00960031  0.0015473  -0.00670272  0.00249614 -0.0037821\n",
      "  0.00708117  0.00064047  0.00356232 -0.0027402  -0.00171121  0.00765576\n",
      "  0.00140822 -0.00585272 -0.00783754  0.00123317  0.00645714  0.00555851\n",
      " -0.00898054  0.0085955   0.00404855  0.00747251  0.00975012 -0.00729241\n",
      " -0.00904347  0.00583827  0.00939486  0.00350829]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv['computer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Dropout 行為:\n",
      "訓練模式輸出和：170.22\n",
      "評估模式輸出和：-198.75\n",
      "\n",
      "2. BatchNorm 行為:\n",
      "訓練模式第1次運行，BatchNorm層的running_mean：-0.0027\n",
      "訓練模式第2次運行，BatchNorm層的running_mean：-0.0015\n",
      "訓練模式第3次運行，BatchNorm層的running_mean：-0.0018\n",
      "評估模式第1次運行，BatchNorm層的running_mean：-0.0018\n",
      "評估模式第2次運行，BatchNorm層的running_mean：-0.0018\n",
      "評估模式第3次運行，BatchNorm層的running_mean：-0.0018\n",
      "\n",
      "3. 梯度計算:\n",
      "訓練模式下，conv層的權重是否有梯度：True\n",
      "評估模式下，使用torch.no_grad()時無法計算梯度\n",
      "\n",
      "主要區別：\n",
      "1. Dropout：在訓練模式下激活，在評估模式下停用。\n",
      "2. BatchNorm：訓練模式更新統計量，評估模式使用固定統計量。\n",
      "3. 梯度計算：訓練模式默認計算梯度，評估模式通常與torch.no_grad()一起使用以提高效率。\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 創建一個簡單的模型來演示\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.conv = nn.Conv2d(1, 20, 5)\n",
    "        self.bn = nn.BatchNorm2d(20)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "# 實例化模型\n",
    "model = SimpleModel()\n",
    "\n",
    "# 1. Dropout 行為\n",
    "print(\"1. Dropout 行為:\")\n",
    "x = torch.randn(1, 1, 28, 28)\n",
    "model.train()\n",
    "y_train = model(x)\n",
    "model.eval()\n",
    "y_eval = model(x)\n",
    "\n",
    "print(f\"訓練模式輸出和：{y_train.sum():.2f}\")\n",
    "print(f\"評估模式輸出和：{y_eval.sum():.2f}\")\n",
    "\n",
    "# 2. BatchNorm 行為\n",
    "print(\"\\n2. BatchNorm 行為:\")\n",
    "model.train()\n",
    "for i in range(3):\n",
    "    y_train = model(torch.randn(1, 1, 28, 28))\n",
    "    print(f\"訓練模式第{i+1}次運行，BatchNorm層的running_mean：{model.bn.running_mean.mean():.4f}\")\n",
    "\n",
    "model.eval()\n",
    "for i in range(3):\n",
    "    y_eval = model(torch.randn(1, 1, 28, 28))\n",
    "    print(f\"評估模式第{i+1}次運行，BatchNorm層的running_mean：{model.bn.running_mean.mean():.4f}\")\n",
    "\n",
    "# 3. 梯度計算\n",
    "print(\"\\n3. 梯度計算:\")\n",
    "model.train()\n",
    "y_train = model(x)\n",
    "y_train.sum().backward()\n",
    "print(f\"訓練模式下，conv層的權重是否有梯度：{model.conv.weight.grad is not None}\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_eval = model(x)\n",
    "    try:\n",
    "        y_eval.sum().backward()\n",
    "    except RuntimeError:\n",
    "        print(\"評估模式下，使用torch.no_grad()時無法計算梯度\")\n",
    "\n",
    "# 主要區別總結\n",
    "print(\"\\n主要區別：\")\n",
    "print(\"1. Dropout：在訓練模式下激活，在評估模式下停用。\")\n",
    "print(\"2. BatchNorm：訓練模式更新統計量，評估模式使用固定統計量。\")\n",
    "print(\"3. 梯度計算：訓練模式默認計算梯度，評估模式通常與torch.no_grad()一起使用以提高效率。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARN: Relocs has not been applied. Please use `-e bin.relocs.apply=true` or `-e bin.cache=true` next time\n",
      "\u001b[?1000;1006;1015l\u001b[?1000;1006;1015l\u001b[?1000;1006;1015l\u001b[?1000;1006;1015lINFO: Analyze all flags starting with sym. and entry0 (aa)\n",
      "INFO: Analyze imports (af@@@i)\n",
      "INFO: Analyze entrypoint (af@ entry0)\n",
      "INFO: Analyze symbols (af@@@s)\n",
      "INFO: Analyze all functions arguments/locals (afva@@@F)\n",
      "INFO: Analyze function calls (aac)\n",
      "INFO: Analyze len bytes of instructions for references (aar)\n",
      "INFO: Finding and parsing C++ vtables (avrr)\n",
      "INFO: Analyzing methods (af @@ method.*)\n",
      "INFO: Recovering local variables (afva@@@F)\n",
      "INFO: Type matching analysis for all functions (aaft)\n",
      "INFO: Propagate noreturn information (aanr)\n",
      "INFO: Use -AA or aaaa to perform additional experimental analysis\n",
      "\u001b[?1000;1006;1015l\u001b[?1000;1006;1015l\u001b[?1000;1006;1015l"
     ]
    }
   ],
   "source": [
    "import r2pipe\n",
    "## 1fd8493153ca3f73f6063a9abdcf28042a005f2018841ddd722e15640ffbf51e\n",
    "r2 = r2pipe.open(\"/home/mandy900619/data/Malware202403/1f/1fd8493153ca3f73f6063a9abdcf28042a005f2018841ddd722e15640ffbf51e\")\n",
    "\n",
    "r2.cmd(\"aaa\")\n",
    "json = r2.cmdj(\"iSj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nullptr 0\n",
      "unknown0 296\n",
      ".zipr_text_0 16381\n",
      ".dynstr 745\n",
      ".gnu.version 116\n",
      ".rela.dyn 264\n",
      ".gnu.version_r 176\n",
      ".dynamic 528\n",
      ".got 48\n",
      ".interp 28\n",
      ".note.gnu.property 32\n",
      ".note.gnu.build-id 36\n",
      ".note.ABI-tag 32\n",
      ".gnu.hash 40\n",
      ".dynsym 1392\n",
      ".rela.plt 1200\n",
      ".rodata 5416\n",
      ".init_array 16\n",
      ".fini_array 8\n",
      ".got.plt 424\n",
      ".data 24\n",
      "zipr_scoop_820 2\n",
      ".eh_frame_hdr 700\n",
      "zipr_scoop_3222 1\n",
      "zipr_scoop_4864 2161\n",
      ".eh_frame 3000\n",
      ".scoop_symtab 306\n"
     ]
    }
   ],
   "source": [
    "for section in json:\n",
    "    print(section[\"name\"], section[\"size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "byteSequence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
